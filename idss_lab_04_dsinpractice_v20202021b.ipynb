{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "e35db2616b3050ed247d14f1a91ece3f",
     "grade": false,
     "grade_id": "cell-9995d325f17152b9",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Introduction to Data Science and Systems 2020-2021<small><small>v20202021b</small></small>\n",
    "## Lab 4: Data Science in practice\n",
    "#### - ***you should submit this notebook on Moodle along with one pdf file (see the end of the notebook and Moodle for instructions)***\n",
    "---\n",
    "#### University of Glasgow\n",
    "\n",
    "\n",
    "$$\n",
    "\\newcommand{\\vec}[1]{ {\\bf #1}} \n",
    "\\newcommand{\\real}{\\mathbb{R}}\n",
    "\\DeclareMathOperator*{\\argmin}{arg\\,min}\n",
    "\\newcommand{\\expect}[1]{\\mathbb{E}[#1]}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "2e4d446431780c6f9a25ba9cb962a1e1",
     "grade": false,
     "grade_id": "cell-32f2e0771a121341",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Purpose of this lab\n",
    "\n",
    "In the lab you will apply some of the data science and systems techniques you have learned about previously. The aim is to use the basic techniques to solve a specific problem related to accessing and storing data in a Panda dataframe. \n",
    "\n",
    "#### Part 1:\n",
    "* revisit how to use Pandas to easily load and inspect a dataset \n",
    "\n",
    "#### Part 2:\n",
    "* implement a solution for compressing the values in the dataset based on PCA\n",
    "\n",
    "####  Part 3:\n",
    "* investigate the relationship between query cardinality and the query itself\n",
    "* sample a set of realistic queries using your knowledge of probability density functions\n",
    "* collect a dataset of queries and cardinality using Pandas \n",
    "* suggest and implement your own solution for predicting the cardinality of the query (using linear algebra)\n",
    "\n",
    "\n",
    "\n",
    "***Notice:*** \n",
    "- This lab is more open-ended than the previous labs and there are fewer step-by-step instructions.\n",
    "- It is a brand new lab so there are bound to be a few glitches, so don't hesitate to ask if you get stuck.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Before you begin\n",
    "\n",
    "Please update the tools we use for the automated grading by running the below command (uncomment) and restart your kernel (and then uncomment again) -- or simply perform the installation externally in an Anaconda/Python prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -U --force-reinstall --no-cache https://github.com/johnhw/jhwutils/zipball/master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "# Make sure you run this cell!\n",
    "from __future__ import print_function, division\n",
    "import numpy as np  # NumPy\n",
    "import scipy.stats \n",
    "import os\n",
    "import pandas as pd\n",
    "import sys\n",
    "import timeit\n",
    "import time\n",
    "import binascii\n",
    "from unittest.mock import patch\n",
    "from uuid import getnode as get_mac\n",
    "\n",
    "from jhwutils.checkarr import array_hash, check_hash, check_scalar, check_string\n",
    "import jhwutils.image_audio as ia\n",
    "import jhwutils.tick as tick\n",
    "\n",
    "###\n",
    "tick.reset_marks()\n",
    "\n",
    "# special hash funciton\n",
    "def case_crc(s, verbose=True):\n",
    "    h_crc = binascii.crc32(bytes(s.lower(), 'ascii'))\n",
    "    if verbose:\n",
    "        print(h_crc)\n",
    "    return h_crc\n",
    "\n",
    "# this command generaties a unique key for your system/computer/account\n",
    "uuid_simple = ((\"%s\") % get_mac())\n",
    "uuid_str = (\"%s\\n%s\\n%s\\n%s\\n%s\\n\") % (os.path,sys.path,sys.version,sys.version_info,get_mac())\n",
    "uuid_system = case_crc(uuid_str,verbose=False) \n",
    "\n",
    "\n",
    "# Set up Matplotlib\n",
    "import matplotlib as mpl   \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rc('figure', figsize=(8.0, 4.0), dpi=140)\n",
    "np.random.seed(2019)\n",
    "\n",
    "# You can ignore this\n",
    "print(\"np\",np.__version__)\n",
    "print(\"pd\",pd.__version__)\n",
    "print(\"Everything imported OK (ignore deprecated warnings)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "e46a494577565c6dc3c0ef7e5b643c9d",
     "grade": true,
     "grade_id": "cell-0f5367ef948a09e5",
     "locked": true,
     "points": 0,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Hidden cell for utils needed when grading (you can/should not edit this)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "dec9268b4d9bcf8c0dc45c4725ad4fa6",
     "grade": false,
     "grade_id": "cell-81b8a494524a0965",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "**Mini-task**: provide your personal details in two variables:\n",
    "\n",
    "* `student_id` : a string containing your student id (e.g. \"1234567x\"), must be 8 chars long.\n",
    "* `student_typewritten_signature`: a string with your name (e.g. \"Adam Smith\") which serves as a declaration that this is your own work (read the declaration of originality when you submit on Moodle)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "79516e854a4c26e66e29570ea98645e6",
     "grade": false,
     "grade_id": "cell-093ae1eb980af8c9",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "student_id = \"\" # your 8 char student id\n",
    "student_typewritten_signature = \"\" # your full name, avoid spceical chars if possible\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1 Loading and inspecting the data\n",
    "The system admins are planning on storing the data in a Panda dataframe (\"the database\") insted of a more traditional database.\n",
    "However, they are concerned about the performance of the Panda-based system and have decided to investigate further."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "f385ff1755519050d1fbfd4138da73b6",
     "grade": false,
     "grade_id": "cell-efa61adcaba08934",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "#### Part 1.1 Download the dataset\n",
    "Download the Covertype Data Set from the UCI repository and save it in a subfolder called data (i.e. when loading you should load from \"./data/covtype.data\")\n",
    "\n",
    "https://archive.ics.uci.edu/ml/datasets/Covertype\n",
    "\n",
    "#### Part 1.2 Loading the dataset\n",
    "Load the dataset in covtype.data into a Panda dataframe and add appropriate headers to the first 11 columns (at least) according to the dataset description (i.e. the first column should be \"Elevation\"). Hint: consider using the \"rename\" method.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "681ec8990e9daf19cb798398a7400f52",
     "grade": false,
     "grade_id": "cell-2c78f3f996910518",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./data/covtype.data\", header=None) # DO NOT CHANGE THIS!\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "5ecba7f015c18d96af2e199ac4af4182",
     "grade": true,
     "grade_id": "cell-9979e8d21e886ee4",
     "locked": true,
     "points": 6,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Check that you have (most likely) the right data set and have added headers.\n",
    "with tick.marks(6):        \n",
    "    assert(np.sum(data['Elevation'].to_numpy()) == 1719426752)    \n",
    "    for i in range(0,11):\n",
    "        assert(isinstance(data.columns[i],str))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 1.3 Basic stats\n",
    "We can use Panda's `describe` function to extract some useful statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "cd427eba97f67af876b4333315d2c50f",
     "grade": false,
     "grade_id": "cell-5f3eef5fcb8b5cfb",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "From the table above, identify the median and mean for the `Elevation` measurements and save the values in variables named `stats_mean_elevation` and `stats_median_elevation` (two decimals). \n",
    "\n",
    "***Hint***: You may need to do a bit of investigation into what the 'describe' function outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "cb90234f5359b93ec66419699510a7a9",
     "grade": false,
     "grade_id": "cell-dc107b8326d7db9a",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "f7fa05889acf48398c6cc0cf18fc38a1",
     "grade": true,
     "grade_id": "cell-f5b94f8a1af750aa",
     "locked": true,
     "points": 4,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "with tick.marks(4):    \n",
    "    assert(check_hash(stats_mean_elevation, ((), 14796.849999999999)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "986da7c1811d87f3c8ba6fd815019e44",
     "grade": true,
     "grade_id": "cell-eecd0ed2c0194f93",
     "locked": true,
     "points": 4,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "with tick.marks(4):    \n",
    "    assert(check_hash(stats_median_elevation, ((), 14980.0)))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "d0bcfd7b29c1985e7b91ed3690f27eea",
     "grade": false,
     "grade_id": "cell-c47ea585c2281e6f",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "fb9eee7409b943a74a27e58b087c4e78",
     "grade": false,
     "grade_id": "cell-26397e6d82858b52",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Part 2 Dataset Compression \n",
    "\n",
    "#### Part 2.1\n",
    "In an attempt to optimise the database the team is looking to use PCA to compress the dataset (i.e. reduce the number of bits we need to store).\n",
    "\n",
    "It is speculated that the following measurements can be represented in a low dimensional space without too much loss of information.\n",
    ">    - 'Elevation'\n",
    ">    - 'Aspect'\n",
    ">    - 'Slope'\n",
    ">    - 'Horizontal_Distance_To_Hydrology'\n",
    ">    - 'Vertical_Distance_To_Hydrology'\n",
    ">    - 'Horizontal_Distance_To_Roadways'\n",
    ">    - 'Hillshade_9am'\n",
    ">    - 'Hillshade_Noon '\n",
    ">    - 'Hillshade_3pm '\n",
    ">    - 'Horizontal_Distance_To_Fire_Points '\n",
    ">    - 'Wilderness_Area[0]'  (meaning only the first of the 4 Wilderness_Area columns)\n",
    " \n",
    "1) Extract the relevant data in a separate numpy array (do not modify the dataframe itself). Demean and standardize the extracted data such that each column has zero mean and a standard deviation of one.\n",
    "\n",
    "2) Compute the PCA (use np.linalg.eig) and determine the minimum number of components required to preserve 70% of variance. Save the number of components in `n_components` (i.e. an integer). The relative contribution from one principle component is measured as $\\frac{\\lambda_i}{\\sum_{j=1}^J \\lambda_j}$ where $\\lambda$ is the eigenvalue for that component and $J$ is the number of eigenvalues.  \n",
    "\n",
    "3) Provide the \"compressed\" version of the data in `data_lowd` with dimension (581012, n_components).\n",
    "\n",
    "\n",
    "***Note:*** There are no visible tests in this part as we expect you will be able to solve this given the knowledge you have acquired in earlier labs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "8a02e49afd547022bb1e59914493c508",
     "grade": false,
     "grade_id": "cell-21b44baf5671898b",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "8fca612b4986cd9c3e986d13d1d52f14",
     "grade": true,
     "grade_id": "cell-bf4be6b5bdb912a1",
     "locked": true,
     "points": 6,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "### Hidden test checking n_components [6 marks]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "2e371cb4d94cbb1ee1e24cd0fe6fbe3e",
     "grade": true,
     "grade_id": "cell-cca3e430deccec88",
     "locked": true,
     "points": 15,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "### Hidden test test checking data_lowd of shape (581012, n_components) [15 marks]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "b74faf2cead9ad1f19e0cfa975288d5a",
     "grade": false,
     "grade_id": "cell-7026d300a1b77df5",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Part 3: Cardinality of the result set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "acd96e733c23f08c46115e5113d9b0c2",
     "grade": false,
     "grade_id": "cell-782a00751d0ff95e",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "#### Part 3.1 Queries\n",
    "The database team is interested in optimising the performance of the system when querying the dataframe. To test the performance, queries are assumed to relate only to the Elevation column and are specified as an interval. For example, a query [2500,2061] would return all entries where the Elevation is between 2500 and 2061.\n",
    "\n",
    "The actual query which is executed by the Panda is then specified as $[a,b]$ or $[c-s/2, c+s/2]$. A couple of probability density functions have been formulated and believed to generate a set of realistic queries. \n",
    "\n",
    "The $c$ value, or the center of the interval, is sampled according to the following probability density function:\n",
    "\n",
    "$$p(c) = 0.3\\cdot Normal(\\,c\\,|\\,2500,50) + 0.4\\cdot Normal(\\,c\\,|\\,3000,100) + 0.3\\cdot Normal(\\,c\\,|\\,3250,80)\\,\\,\\,\\,\\,\\,\\,\\,\\, (Eq. 1)$$  \n",
    "\n",
    "Thus $p(c)$ is made up of three so-called components with each component being a Normal distribution parameterised by the mean and standard deviation.\n",
    "\n",
    "The $s$ (the size of the interval) is sampled according to the following probability density function:\n",
    "\n",
    "$$p(s) = Gamma(s|8,25)\\,\\,\\,\\,\\,\\,\\,\\,\\,  (Eq. 2)$$\n",
    "\n",
    "where the parameters are the shape and scale, respectively. Gamma is a special probability distribution which you should lookup.\n",
    "\n",
    "***Note:*** There is not a specific question here - you just have to examine the equations and the various distributions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "00422263efda9c011309f68ac791cfc2",
     "grade": false,
     "grade_id": "cell-912c3a82a980cf55",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "#### Part 3.2 Sample a set of queries\n",
    "You must now complete a function which can sample 2000 queries from the query distribution defined by Eq. (1) and Eq. (2).\n",
    "\n",
    "Save the queries $[c,s]$ as rows in `X` (i.e. `X` should be of size (2000,2) ).\n",
    "\n",
    "***Hint***: You are looking to sample from these distribution; not compute the density (i.e. you should not implement the equations per se). For $p(c)$, first sample a component with the given probability, then sample from that component. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "f61a1c93c7b81b1375615b7e3fb731f1",
     "grade": false,
     "grade_id": "cell-0995055f41f0bbb7",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def sample_queries(N=2000):    \n",
    "        \n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's sample..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1111) # you may wan tto provide a seed to consistent results\n",
    "X = sample_queries(N=2000)\n",
    "\n",
    "fig = plt.figure(figsize=(5,5))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "ax.hist(X[:,0])\n",
    "ax.hist(X[:,1])\n",
    "ax.legend(('c','s'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "56565af8b616bbbdd1cb7427db08aea2",
     "grade": true,
     "grade_id": "cell-a4fc0cc3171210a4",
     "locked": true,
     "points": 10,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Note this test only ensure that you you have sensible sampler\n",
    "# - it is not absolute evidence \n",
    "# that your sampler is exactly as specified (you should make \n",
    "# extra sure to test your implementation)\n",
    "#\n",
    "# You sampler will be checked manually when marking against a more \n",
    "# extentive test and you marks are thus tentative!\n",
    "#\n",
    "\n",
    "with tick.marks(10):        \n",
    "    query_function_is_likely_correct = False\n",
    "    for irep in range(0,3): # repeat a few times to make it wasn't a lucky run\n",
    "        for n in [100000]:\n",
    "            samples = sample_queries(n)\n",
    "            assert samples.shape == (n,2)\n",
    "            assert np.min(samples[:,0]) > 0\n",
    "            assert np.min(samples[:,1]) > 0            \n",
    "            qc  = np.quantile(samples[:,0], np.linspace(0.1,0.95,10))\n",
    "            qs  = np.quantile(samples[:,1], np.linspace(0.1,0.95,10))                                                    \n",
    "            qc_true = np.array([2478.04573054, 2518.19126684, 2588.47755615, 2917.62945017,\n",
    "            2984.9975373 , 3045.53633682, 3117.29174297, 3193.0221899,\n",
    "            3255.41404674, 3327.7111032])            \n",
    "            qs_true =  np.array([116.55924418, 138.49041163, 155.92921611, 171.96901016,\n",
    "            187.79187985, 204.68888341, 223.16652347, 245.08779129,\n",
    "            275.02758806, 328.7319762])            \n",
    "            assert( np.all( np.abs(qc_true - qc) < 25 ))\n",
    "            assert( np.all( np.abs(qs_true - qs) < 10 ))                \n",
    "    \n",
    "    query_function_is_likely_correct = True\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "9fdcc5c420e521cbcc104ef93d18f402",
     "grade": true,
     "grade_id": "cell-2d324aca7156bc29",
     "locked": true,
     "points": 0,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# A placeholder for the automarker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "30dd8373ec3a029375da62965dd74995",
     "grade": false,
     "grade_id": "cell-b3aabd98565b0c75",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "#### Part 3.3 Execute a single query \n",
    "You must now complete a function which can execute a single query based on the start and end points of the interval, [a,b], against the database (in this case a Panda dataframe stored in the variable named ´data´)\n",
    "\n",
    "The function must return:\n",
    "- the time taken in seconds (already provided), t\n",
    "- the cardinality of the result set, n\n",
    "- the result set, i.e. all rows where $a=c-s/2 \\leq Elevation \\leq b=c+s/2$\n",
    "\n",
    "***Hint***: You may need to consult the documentation for Panda to find a suitable command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "186501d9ed3ffa902f814d85aabb800d",
     "grade": false,
     "grade_id": "cell-931efd92fa66bb67",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def query(a,b):    \n",
    "    tic=timeit.default_timer()    \n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    toc=timeit.default_timer() \n",
    "    t = toc - tic \n",
    "    return t, n, res          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "6b8054bf06f45a97a8c72c331aec1295",
     "grade": true,
     "grade_id": "cell-6bd97db3ea240b1b",
     "locked": true,
     "points": 5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "with tick.marks(5): \n",
    "    query_function_is_correct = False\n",
    "    t, n, res = query(2967.0,2967.5)\n",
    "    z = np.sum(res['Aspect'].to_numpy())    \n",
    "    assert( n == 762 )\n",
    "    assert( z == 121183 )\n",
    "    query_function_is_correct = True\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "b25c03b510321888989cbf06135ebfe3",
     "grade": false,
     "grade_id": "cell-4c8c28d4cf0c6b0c",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "#### Part 3.4 Execute and time all queries\n",
    "\n",
    "You should now execute all the queries in `X` against the database by calling the function `query`. Queries should be read from the `X` array previously generated.\n",
    "\n",
    "The resulting data should be collected in two numpy arrays:\n",
    "\n",
    "- `y_times` with shape (2.000,1) holding the times measured for each query\n",
    "- `y_cardinality` with shape (2.000,1) holding the size of the result set for each query\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "abe784722be4b4748f80d39ec8660b23",
     "grade": false,
     "grade_id": "cell-b13bb6f2780234a1",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "N = np.shape(X)[0]\n",
    "y_times = np.zeros((N,1))\n",
    "y_cardinality = np.zeros((N,1))\n",
    "\n",
    "# Hint remember that you need to parse a and b to query (not c and s)\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "3310cb0f6fbbda701b6ebd07309efdfe",
     "grade": true,
     "grade_id": "cell-469ab2097f0a3b5c",
     "locked": true,
     "points": 6,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Hidden test (make sure you test your function carefully!) [5 marks]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "c521d0d8e35bd7301fa9731a4906208f",
     "grade": false,
     "grade_id": "cell-8cd49cc1e4367a20",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "We can then plot the distribution of the cardinality measurements... Validate that the histogram looks like you expect.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(4,4)) \n",
    "ax = fig.add_subplot(1,1,1) \n",
    "ax.hist(y_cardinality)\n",
    "ax.set_xlabel('Value')\n",
    "ax.set_ylabel('Count')\n",
    "ax.set_title('Orginal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "ab85d6b76e65c031ef257cd08734a823",
     "grade": false,
     "grade_id": "cell-cd01255ed99c002f",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "#### Part 3.5 Save the data for later use (and for testing/validation )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez('datalog.npz', X=X,y_times=y_times,y_cardinality=y_cardinality)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "8bd6144256fb8c37028ad5814a06db52",
     "grade": false,
     "grade_id": "cell-06eca23562090ccf",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "#### Part 3.6 Map from query to cardinality\n",
    "We are now interested in specifying a function which can map from a query (i.e. x=[c,s]) to the query cardinality for this database (i.e the Panda dataframe).\n",
    "\n",
    "The function is pre-defined as:: \n",
    "\n",
    "$$f(x;\\theta ) = {w_0} + {w_1}c + {w_2}s + {w_3}{c^2} + {w_4}{s^2} + {w_5}{c^3} + {w_6}{s^3} + {w_7}{c^4} + {w_8}{s^4} + {w_9}\\cdot c \\cdot s \\,\\,\\,\\,\\,\\,\\,\\, (Eq. 3)$$\n",
    "\n",
    "where x is a query which is mapped through f to the query cardinality. The loss defined as \n",
    "\n",
    "$$L\\left( \\theta  \\right) = \\frac{1}{N} \\sum\\limits_{n = 1}^{N=2000} {{{\\left( { {y_n} - f({x_n};\\theta )} \\right)}^2}} $$\n",
    "\n",
    "You should now complete four classes/methods that the database team use in their estimation:\n",
    "\n",
    "- `output_process` \n",
    "- `input_process`\n",
    "- `predict`\n",
    "- `estimate`\n",
    "- `evaluate`\n",
    "\n",
    "**Hint**: It is recommend that you write the function in matrix form (use pen and paper) before attempting to implement it.\n",
    "\n",
    "Any method you implement must be based on pure Python and numpy (i.e. **you cannot use scikit learn or similar tools**).\n",
    "\n",
    "\n",
    "**Marking:** The overall marking is based on whether you manage to a) beat a baseline prediction, and b) come close to the correct solution. There are intermediate marks to help you along.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "783d4f28cae97d2ee022f72ea26465af",
     "grade": false,
     "grade_id": "cell-78e99e55fdd57ba5",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Load the generated data from the file\n",
    "# This makes it easier to mark and debug your solution at marking time\n",
    "# Hint: If you struggle to generate meaningful data in the previous part you can \n",
    "# copy the content of the cell to a new cell and load the file called datalog_demo.npz \n",
    "# which contains pre-generated observations.\n",
    "\n",
    "tmp = np.load('datalog.npz')\n",
    "X = tmp['X']\n",
    "y_cardinality = tmp['y_cardinality']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "9198c7efb0f52be785ac24256794053f",
     "grade": true,
     "grade_id": "cell-bd81dda79aea951d",
     "locked": true,
     "points": 0,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# A placeholder for the automarker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "b1eb3f72441fa5ddb26d5efd8c1930b1",
     "grade": false,
     "grade_id": "cell-d9c7797c9a3869f2",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "#### Part 3.7 Input and output processing\n",
    "Complete the `input_process` class for preprocessing the inputs, X (e.g. normalisaiton and other transforms of X). \n",
    "\n",
    "- `output_process`: is already provided and you shouldn't need to modify it. \n",
    "- `input_process`: you probably need to inspect the other functions and cells below (e.g. predict) to work out what to put here.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "d84a87676d1fbf3feba164270b97c4cc",
     "grade": false,
     "grade_id": "cell-694b9deccaa54349",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "class output_process:    \n",
    "    \"\"\"\n",
    "    A simple helper class which containes two functions for removing the mean of y and \n",
    "    adding it at prediction time \n",
    "    \n",
    "    Requirement: y = rescale(scale(y))    \n",
    "                        \n",
    "    \n",
    "    \"\"\"\n",
    "    y_mean = None # these are just proposals, you can modify the variables function as you se fit depending on if and how you wish to \n",
    "    y_std = None\n",
    "    \n",
    "    def __init__(self, y):                \n",
    "        self.y_mean = 0 # this is a trick, it is only 0 for now\n",
    "        self.y_mean = np.mean(self.scale(y),axis=0)        \n",
    "        \n",
    "    def scale(self,y):        \n",
    "        \"\"\"\n",
    "        A function which scales/tranforms the y values, e.g. subtracting the mean.\n",
    "        \"\"\"       \n",
    "        y_prime = y - self.y_mean                \n",
    "        return y_prime\n",
    "    \n",
    "    def rescale(self,y_prime):\n",
    "        \"\"\"\n",
    "        A function which re-scales/tranforms the y_prime value back to the orginal domain (e.g. undoes the effect of scale)\n",
    "        E.g., adding a constant such as the mean.\n",
    "        \n",
    "        \"\"\"        \n",
    "        y = y_prime + self.y_mean         \n",
    "        y[y<0]=0  # avoid negative predictions          \n",
    "        return y         \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "4d92256f235f36ff3dc165612b0f0573",
     "grade": false,
     "grade_id": "cell-fd958952595f7cf5",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "class input_process:   \n",
    "    \"\"\"    \n",
    "    A simple class which contains two functions for processign the 2D observation of the query x=(c,s) \n",
    "    and returns a potentailly scaled, normalised and expanded representation.                         \n",
    "    \"\"\"\n",
    "    X_mean = None # proposal; the usage depends on you decicion to normalise X or not    \n",
    "    X_std  = None # proposal; the usage depends on you decicion to standardise X or not    \n",
    "        \n",
    "    def __init__(self, X):         \n",
    "        self.X_mean = 0 # this is a trick, it is only 0 for now\n",
    "        self.X_std  = 1 # this is a trick, it is only 1 for now\n",
    "        self.X_mean = np.mean(self.process(X)[:,1:] ,axis=0)                \n",
    "        self.X_std  = np.std(self.process(X)[:,1:] ,axis=0)                \n",
    "                    \n",
    "    def process(self,X):\n",
    "        \"\"\"\n",
    "        A function which takes the 2D in and processes the data, e.g. make a basis expansion and \n",
    "        standaise the result.\n",
    "        \n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "        return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "fee7ee59084aab28538a34e982f2d763",
     "grade": false,
     "grade_id": "cell-55f01d1be37d107a",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "##### Input process:\n",
    "\n",
    "We can apply the input process to query and observe the effect. This is the tricky bit so make sure to validate that input_process works as intended (there are no automated test to check this!).\n",
    "\n",
    "**Note**: If you have done this the recommend/intended way, the output would not be 2D for each observations but rather 10D."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inprocess = input_process(X)\n",
    "x_demo = inprocess.process(X[0:3,:]) # take 3 queries and see what happens to them\n",
    "print(x_demo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "56f96a985a5af70a6bd2b7e00e09ad21",
     "grade": false,
     "grade_id": "cell-bcf8a9f1be9bcb7f",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "#### Part 3.8 Predict \n",
    "Implement a function that can predict the cardinality, $y$, of a query $x=[c,s]$ based on Eq. (3). The parameters are stored in `theta` (i.e. $w \\in \\mathbb{R}^{10}$), using only linear algebra/vector operations and calls to the relevant input and output process functions (these are shown). \n",
    "\n",
    "The function should return the estimate of the cardinality in $y$, and the scale prediction in y_prime. It must be able to make predictions for multiple observations in `X` (i.e. `X` is a matrix)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "5c0d76c89ba875bc547e0b57aac5357a",
     "grade": false,
     "grade_id": "cell-dfd4b8229a29f9c3",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def predict(X, theta, output_process,input_process):      \n",
    "    if input_process is not None: # note we use None when testing/marking\n",
    "        X = input_process.process(X)\n",
    "    \n",
    "    # Hint: Only a single line of code is missing\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    if output_process is not None: # note we use None when testing/marking\n",
    "        y = output_process.rescale(y_prime)\n",
    "    else:\n",
    "        y = y_prime\n",
    "        \n",
    "    return y, y_prime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "a3d128a02d78e12439926aef68302c48",
     "grade": true,
     "grade_id": "cell-0d196fc6036aa3dd",
     "locked": true,
     "points": 5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Hidden test validating the predict function [5 Marks]\n",
    "# Test which test the core functionality of the predict function (it dones't test the input and output process)\n",
    "\n",
    "with tick.marks(5):\n",
    "    X_test = np.array([[1.2,8.54],[2.4,4.5]])\n",
    "    theta = np.array([0.50722768, -1.32649421])\n",
    "    y_test, y_prime_test = predict(X_test, theta, None, None)\n",
    "        \n",
    "    assert(check_hash(y_test, ((2,), -48.182417152)))\n",
    "    assert(check_hash(y_prime_test, ((2,), -48.182417152)))    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "84b5101f8f61fd532f110adb9ee3d2f4",
     "grade": false,
     "grade_id": "cell-362c2123b19d7fa6",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "#### Part 3.9\n",
    "Write a function which computes the mean squared error (mse) based on the difference between the predicted and true query cardinality. It should also return the mean absolute error and the relative absolute error (in percent) wrt to the actual observation for the absolute error (i.e. how many percent is the prediction wrong on average).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "f17e920544e0221f4d81fc70c90511a3",
     "grade": false,
     "grade_id": "cell-a15bc1f838a90a81",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def evaluate(y_pred,y_true):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return error_mse, error_abs, error_abs_relative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "cc1b2c4211d138cfbc942db29da37f66",
     "grade": true,
     "grade_id": "cell-454b7f841eccafd1",
     "locked": true,
     "points": 5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Test checkign the evaluate function\n",
    "with tick.marks(5):\n",
    "    a,b,c = evaluate(np.array([4.5,6.2,-100.10]), np.array([14.5,-26.2,-110.10]))    \n",
    "    assert(check_hash(a, ((), 2082.9333333333334)))\n",
    "    assert(check_hash(b, ((), 87.33333333333333)))\n",
    "    assert(check_hash(c, ((), -106.30209505074754)))      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "480b0443c50464c88cf32a0f58689f70",
     "grade": false,
     "grade_id": "cell-cad2f60441371ba2",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "#### Part 3.10\n",
    "Implement a function which estimates the parameters, i.e., the $w$'s stored in `theta`, of the function based on the squared error loss defined above.\n",
    "\n",
    "Hint: This should be done using only matrix operations and calls to the input/output process functions. You don't need numerical optimisation for this.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "b5093873aaeff189581fe3c46779218d",
     "grade": false,
     "grade_id": "cell-7be538ae4967aedd",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def estimate(X, y, outprocess, inprocess):\n",
    "    \"\"\"\n",
    "    X: 2D queries/observations \n",
    "    y: observed cardinality (the orginal ones, i.e. not scaled or normalised) \n",
    "    outprocess: an instance of the output process class which is used to scale and rescale y\n",
    "    inprocess: an instance of the input process class which is used to process the 2D input in X in a sensible way\n",
    "    \"\"\"        \n",
    "    if outprocess is not None: # note we use None when testing/marking\n",
    "        y = outprocess.scale(y)\n",
    "        \n",
    "    if inprocess is not None: # note we use None when testing/marking\n",
    "        X = inprocess.process(X)\n",
    "    \n",
    "    # Hint: 2-3 lines of code missing\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "3ae7a0f26682e61fc49c177a6cdaf7ff",
     "grade": true,
     "grade_id": "cell-a2237df87f9d5cee",
     "locked": true,
     "points": 7,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Hidden test validating the estimate function[5 MARKS]\n",
    "with tick.marks(7):\n",
    "    X_test = np.array([[1.2,8.54,9.77],[2.4,4.5,-33.2]])\n",
    "    y_yest = np.array([1,2])    \n",
    "    theta_test = estimate(X_test, y_yest, None, None)\n",
    "    assert(check_hash(theta_test, ((3,), 0.5095082848719855)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "e043262c7420e0b90bdf301a8bb249cf",
     "grade": false,
     "grade_id": "cell-07d25aaa67811129",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "#### Part 3.11\n",
    "\n",
    "We can now put it all together and check if we are able to make sensible fit to the data.\n",
    "\n",
    "Note: It might be necessary to revisit your implementation above in case you do not get a sensible fit in the first attempt.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "49e0b9a179c7257fb1f1a415b11ce404",
     "grade": false,
     "grade_id": "cell-4c97d8859edb6d96",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "inprocess = input_process(X)\n",
    "outprocess = output_process(y_cardinality)\n",
    "theta = estimate(X,y_cardinality,outprocess,inprocess)\n",
    "y_pred, y_prime_pred = predict(X, theta, outprocess,inprocess)\n",
    "error_mse, error_abs, error_abs_rel = evaluate(y_pred,y_cardinality)\n",
    "\n",
    "print(\"The mse error is: \", error_mse)\n",
    "print(\"The abs error is: \", error_abs)\n",
    "print(\"The releative abs error is [pct]: \", error_abs_rel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "cc6ca79b56c6915cd021c44daac6d765",
     "grade": false,
     "grade_id": "cell-475f10c2e1f5113d",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "#### Part 3.12\n",
    "\n",
    "To evaluate the quality of your fit it is often useful to produce visualisation to aid our analysis. For this purpose you should now:\n",
    "\n",
    "- Create a plot of the cardinality vs the ones estimated by the model. Include a line to illustrate the ideal prediction.\n",
    "- Create a figure showing the distribution of errors\n",
    "- Create a figure visualising the squared error against the the query cardinality \n",
    "\n",
    "\n",
    "Note: These are not assessed per se but suggested for your benefit. They will be written to the pdf file and inspected manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "d0b899f22fe5a5358ec6d4d346778eed",
     "grade": false,
     "grade_id": "cell-d407661871bc34fe",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "fig_312a = plt.figure(figsize=(5,5)) # DO NOT CHANGE\n",
    "ax_312a = fig_312a.add_subplot() # DO NOT CHANGE - YOU MUST ADD YOUR FIGURE TO THIS AXIS\n",
    "#######################################################\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "7996d574dbe0661f265fe478fa6028d2",
     "grade": false,
     "grade_id": "cell-3a4014d0843bcb41",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "fig_312b = plt.figure(figsize=(5,5)) # DO NOT CHANGE\n",
    "ax_312b = fig_312b.add_subplot(1,1,1) # DO NOT CHANGE - YOU MUST ADD YOUR FIGURE TO THIS AXIS\n",
    "#######################################################\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "236159df81513534976a15411b7c1a83",
     "grade": false,
     "grade_id": "cell-31a7db9c3ab88a1d",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "fig_312c = plt.figure(figsize=(5,5)) # DO NOT CHANGE\n",
    "ax_312c = fig_312c.add_subplot(1,1,1) # DO NOT CHANGE - YOU MUST ADD YOUR FIGURE TO THIS AXIS\n",
    "#######################################################\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "80de18636875be587fa65d3546565fc2",
     "grade": false,
     "grade_id": "cell-9144be00830ee47d",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "#### Part 3.13 Baselines\n",
    "To determine if your model is worth deploying and using for estimating the database load, your database team has requested you compare your function/fit to a naiive baseline.\n",
    "\n",
    "\n",
    "The two baseline are:\n",
    "- a) use the mean of the observation as the prediction for all queries \n",
    "- b) use the median of the observation as the prediction for all queries.   \n",
    "\n",
    "Complete the `predict_average` and `predict_median` function below and compare with your predictive model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "73080363f6dfc05982b848335df7563e",
     "grade": false,
     "grade_id": "cell-48d18c20fb902f2f",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def predict_average(y):    \n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return y_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "fe9a37d1d6f4e5e3c3049892bb7ed099",
     "grade": false,
     "grade_id": "cell-08c75b6ec3984876",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def predict_median(y):    \n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return y_med"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "d0067ff1ecf94c6e52ac5882add54ab4",
     "grade": true,
     "grade_id": "cell-61554637c0d4684d",
     "locked": true,
     "points": 4,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Check that the baselines work as expected\n",
    "with tick.marks(4):\n",
    "    baseline_is_corrrect= False\n",
    "    y_test = np.array([-3.4, 3, 6.2, 10])\n",
    "    y_test_avg = predict_average(y_test)    \n",
    "    y_test_median = predict_median(y_test)\n",
    "    assert(check_hash(y_test_avg, ((), 19.75)))\n",
    "    assert(check_hash(y_test_median, ((), 23.0)))\n",
    "    baseline_is_corrrect = True\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "84dc80a05b25f21b2cd59bfe3c387329",
     "grade": false,
     "grade_id": "cell-81a0981a551cc68f",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Evaluate the baselines\n",
    "\n",
    "y_pred_bl = predict_average(y_cardinality)\n",
    "error_mse_bl, error_abs_bl, error_abs_rel_bl = evaluate(y_pred_bl,y_cardinality)\n",
    "print(\"The mse error is: \", error_mse_bl)\n",
    "print(\"The abs error is: \", error_abs_bl)\n",
    "print(\"The relative abs error is [pct]: \", error_abs_rel_bl)\n",
    "\n",
    "y_pred_blmed = predict_median(y_cardinality)\n",
    "error_mse_bl, error_abs_bl, error_abs_rel_bl = evaluate(y_pred_blmed,y_cardinality)\n",
    "print(\"The mse error is: \", error_mse_bl)\n",
    "print(\"The abs error is: \", error_abs_bl)\n",
    "print(\"The relative abs error is [pct]: \", error_abs_rel_bl)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall marking of your function..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "564360389e80aeba45af909b5768c962",
     "grade": true,
     "grade_id": "cell-ba54b9bebe0b55f9",
     "locked": true,
     "points": 5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Hidden test, you get 5 marks for beating the median baseline (the baseline needs to be correct for any marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "1104800904067eb1365d02956d2815ae",
     "grade": true,
     "grade_id": "cell-8535d8f72253afc8",
     "locked": true,
     "points": 18,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "## Hidden test, you'll get 18 marks for obtaining a competetive performance close to our implementation \n",
    "# You'd need munually validation that you have obtained is a sensible and competetive solution.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### No more assessed questions... remember to generate the pdf!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3.X: Optional challenges\n",
    "Several improvements could be considered for the function/implementation in Part 3:\n",
    "- The function we have specified in Eq. (3) is unlikely to be the best option for this purpose. You may want to try the neural network we implemented in Lab 2 - or perhaps other variations of the function suggested. \n",
    "- The cardinality is an integer, but our prediction function does not take that into account (we could consider ordinal regression). \n",
    "- We handle the negative predictions by truncating the predictions; ideally, this should be inherent to the model (i.e., via the loss function).\n",
    "- The function we have fitted probably only works well for the specific query dataset; we should test it on an unseen query dataset - or at least held-out-queries from the current dataset - to make sure it generalizes.\n",
    "- Can you also predict the query time using this approach?\n",
    "- ...\n",
    "\n",
    "We would be happy to look over notebooks addressing these issues, but you will not get extra credit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "12aee4e12a7a9c97e15b2cb6f0a3c2da",
     "grade": false,
     "grade_id": "cell-fb244b3ca5c934eb",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "819034820d13eb57a270260b4099c1f5",
     "grade": false,
     "grade_id": "cell-d08d4a75c8006022",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Submission on Moodle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "5bfa08f78a7ebed65f3504fdba32ea4e",
     "grade": false,
     "grade_id": "cell-6c7b3819abd32986",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "\n",
    "We will generate the **one** pdf file you'll need to submit **along** with the notebook. **DO NOT RENAME THE FILES!**\n",
    "\n",
    "*Note*: you do not need to worry about the formatting etc (that's predetermined)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "84616dc8f49dc884636c3d7ff64eff85",
     "grade": false,
     "grade_id": "cell-b36e056221228fa7",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "## Report generation - YOU MUST YOU RUN THIS CELL !\n",
    "#\n",
    "# Ignore warnings regarding fonts\n",
    "#\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "# Declaration of originality with system info\n",
    "try:\n",
    "    f = open('uofg_declaration_of_originality.txt','r')\n",
    "    uofg_declaration_of_originality = f.read()\n",
    "except: \n",
    "    uofg_declaration_of_originality = \"uofg_declaration_of_originality not present in cwd\"\n",
    "\n",
    "try:\n",
    "    student_id.lower()\n",
    "except: \n",
    "    student_id=\"NORESPONSE\"\n",
    "try:\n",
    "    student_typewritten_signature.lower()\n",
    "except: \n",
    "    student_typewritten_signature=\"NORESPONSE\"\n",
    "\n",
    "fn = (\"idss_lab_04_dsinpractice_%s_declaration.pdf\" % (student_id.lower()))\n",
    "fig_dec = plt.figure(figsize=(10, 12)) \n",
    "fig_dec.text(0.1,0.1,(\"%s\\n\\n Student Id %s\\n\\n Typewritten signature: %s\\n\\n UUID System: %s\" % (uofg_declaration_of_originality,student_id, student_typewritten_signature, uuid_system)))\n",
    "    \n",
    "# Combined: \n",
    "fn = (\"idss_lab_04_dsinpractice_%s_combined_v20202021b.pdf\" % (student_id))\n",
    "pp = PdfPages(fn)\n",
    "pp.savefig(fig_312a)\n",
    "pp.savefig(fig_312b)\n",
    "pp.savefig(fig_312c)\n",
    "pp.savefig(fig_dec)\n",
    "pp.close()\n",
    "\n",
    "with tick.marks(0):  # have you generated the combined file...? you don't actually get any credit for this; just confirmation that the file has been generated\n",
    "    assert(os.path.exists(fn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "175ed02c3298938e72501c0f30efd2fa",
     "grade": false,
     "grade_id": "cell-c32d892a2f810ab0",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "**You must (for full or partial marks) submit TWO files via Moodle:**\n",
    "\n",
    "- this notebook (completed) after \"Restart and rerun all\":\n",
    "    - `idss_lab_04_dsinpractice_v20202021b.ipynb`\n",
    "    \n",
    "- the combined pdf (autogenerated) containing the relevant figures and answers for the manual marking:\n",
    "     - `idss_lab_04_dsinpractice_[YOUR STUDENT ID]_combined_v20202021b.pdf`)     \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "7436c9f8aa2f3b86c17ec7e36bc6b1a3",
     "grade": false,
     "grade_id": "cell-530afe415c5eb50f",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "b5d60dd0ad1fe8165cf318b6b31b3401",
     "grade": false,
     "grade_id": "cell-b0ccdfd6f69b03dc",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Appendix: Marking Summary (and other metadata)\n",
    "#### - make sure the notebook runs without errors (remove/resolve the `raise NotImplementedError()`) and \"Restart and Rerun All\" cells to get a correct indication of your marks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "2153b46ed2deb494a72210a383155341",
     "grade": true,
     "grade_id": "cell-1fa128795b30c9c3",
     "locked": true,
     "points": 0,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "print(\"Marks total : \",\"100\")\n",
    "print(\"Marks visible (with immediate feedback): \",\"50\")\n",
    "print(\"Marks hidden (without immediate feedback): \",\"50\")\n",
    "print(\"\\nThe fraction below displays your performance on the autograded part of the lab that's visible with feedback (only valid after `Restart and Run all`:\")\n",
    "tick.summarise_marks() # "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "62b80f500969c62bc0628a90ad41eea6",
     "grade": false,
     "grade_id": "cell-9a26f6437b8f2a62",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
